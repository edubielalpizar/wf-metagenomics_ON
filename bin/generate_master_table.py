#!/usr/bin/env python3
"""Script to split fastq by taxid using the output of centrifuge."""
import argparse
from collections import namedtuple
from functools import partial
from pathlib import Path
import urllib.parse

import ncbitaxonomy
import pandas as pd


NCBI = ncbitaxonomy.NCBITaxa()
RANKS = [
    "superkingdom",
    "kingdom",
    "phylum",
    "class",
    "order",
    "family",
    "genus",
    "species",
]

Rule = namedtuple("Rule", ["dirname", "function", "taxid"])


parser = argparse.ArgumentParser(
    description=(
        "Script to split fastq by taxid using the output of centrifuge."
    )
)
parser.add_argument(
    "read_classification", type=Path, help="File produced by centrifuge"
)
parser.add_argument(
    "fastcat_output", type=Path, help="File produced by fastcat"
)
parser.add_argument("outdir", type=Path, help="Directory to place results")
parser.add_argument(
    "--delimiter",
    default="|",
    help="Delimiter to separate user specified label groups "
    "and autogenerated labels",
)
parser.add_argument(
    "--human",
    action="store_true",
    help="Output human friendly names for files",
)
split_type = parser.add_mutually_exclusive_group(required=True)
split_type.add_argument(
    "--rank",
    choices=RANKS,
    help=(
        "Group fastq by a specific rank.  Note: all "
        "reads classified above this level will be grouped in one group."
    ),
)
split_type.add_argument(
    "--taxid",
    type=int,
    help=(
        "Group reads classified at this rank and below in one file. "
        "Produces taxid group, unclassified and other."
    ),
)
split_type.add_argument(
    "--classified",
    action="store_true",
    default=False,
    help=(
        "If selected, reads that were successfully classified "
        "will be grouped separately from unclassified reads."
    ),
)
split_type.add_argument("--split", help="split rule string")


def _get_ranked_lineage(taxid):
    if not taxid:
        return {}
    try:
        lineage = NCBI.get_rank(NCBI.get_lineage(taxid))
        return {r: str(t) for t, r in lineage.items() if r in RANKS}
    except ValueError:
        # This will happen if the ID is not found or the dbs are out of date
        return {}


def _create_lineage_master(taxids):
    return pd.DataFrame(
        (_get_ranked_lineage(taxid) for taxid in taxids),
        index=taxids,
        columns=RANKS,
    )


def _get_lineage(taxid):
    try:
        return NCBI.get_lineage(int(taxid))
    except ValueError:
        return {}


def by_rank(tax_groups, rank="genus"):
    """
    Label by rank.

    Create a dict containing {Original taxid: Label to add} where the label is
    what rank you've chosen.

    :param tax_groups: set of taxids
    :param rank: at what rank you wish to normalise to e.g. "genus"
    :return: a dictionary of {taxid: taxid_at_rank OR other or unclassified}
    """
    return {
        taxid: "unclassified"
        if not taxid
        else _get_ranked_lineage(taxid).get(rank, "other")
        for taxid in tax_groups
    }


def by_taxid(tax_groups, selected_taxid):
    """
    Label by taxid.

    Create a dict containing {Original taxid: Label to add} where the label is
    whether the original taxid is at the same level or lower than the selected.
    taxid.

    :param tax_groups: set of taxid (integer)
    :param selected_taxid: comma sep string of taxids
    :return: a dictionary of {taxid: selected taxid OR other OR unclassified}
    """
    selected_taxid = int(selected_taxid)
    return {
        taxid: selected_taxid
        if _get_lineage(int(taxid))
        and selected_taxid in NCBI.get_lineage(int(taxid))
        else "unclassified"
        if taxid == 0
        else "other"
        for taxid in tax_groups
    }


def by_status(tax_groups):
    """
    Label by status.

    Create a dict containing {Original taxid: Label to add} where the label is
    whether the taxid constitutes a classification (anything missing a taxid).

    :param tax_groups: set of taxids
    :return: a dictionary of {taxid: classified OR unclassified}
    """
    return {
        taxid: "unclassified" if not taxid else "classified"
        for taxid in tax_groups
    }


def _generate_rules(rule_str):
    """
    Generate a set of Rules from a rule string.

    :param rule_str:
    :return: an iterable of Rules
    """
    for individual_rule_str in rule_str.split(" "):
        try:
            dirname, func_lab, value = individual_rule_str.split(":")
        except ValueError:
            dirname, func_lab = individual_rule_str.split(":")
            value = "1"
        if func_lab in RANKS:
            func = partial(by_rank, rank=func_lab)
            yield Rule(dirname, func, int(value))
        elif func_lab == "taxid" or "":
            for value in value.split(","):
                func = partial(by_taxid, selected_taxid=int(value))
                yield Rule(dirname, func, int(value))
        else:
            raise Exception("Who knows what happened here...")


def by_rule(tax_groups, rules, human=True, delimiter="|"):
    """
    Partition data by rule string.

    :param tax_groups: set of taxids
    :param rules: rule string (Rule)
    :param human: replace labels with human readable rather than just taxid
    :param delimiter: "delimiter for group label vs individual label"
    :return: a dictionary of {taxid: label}
    """

    def _get_name(taxid) -> str:
        if not human:
            return f"{taxid}"
        taxid_int = int(taxid)
        return urllib.parse.quote(
            NCBI.get_taxid_translator([taxid_int])[taxid_int], safe=" "
        )

    others = {t for t in tax_groups if t}
    assignments = {0: f"unclassified{delimiter}unclassified"}

    for rule in _generate_rules(rules):
        if not others:
            break

        tax_group_subset = [
            t for t in others if rule.taxid in NCBI.get_lineage(int(t))
        ]
        named_assignments = {
            k: f"{rule.dirname}{delimiter}{_get_name(v)}"
            for k, v in rule.function(tax_group_subset).items()
            if v != "other"
        }
        others -= named_assignments.keys()
        assignments = {**named_assignments, **assignments}

    return {
        t: assignments.get(t, f"other{delimiter}other") for t in tax_groups
    }


def main():
    """Generate master table."""
    args = parser.parse_args()
    tsv_path = args.read_classification
    fastcat_output = args.fastcat_output
    output_dir = args.outdir
    split_by_rank = args.rank
    split_by_taxid = args.taxid
    split_by_status = args.classified
    split_by_rule = args.split
    human_labels = args.human
    delimiter = args.delimiter

    output_dir.mkdir(exist_ok=True)

    if not tsv_path.is_file:
        raise FileNotFoundError
    elif split_by_taxid is not None and int(split_by_taxid) <= 0:
        raise Exception(f"Invalid taxid: {split_by_taxid}")
    elif not fastcat_output.is_file:
        raise FileNotFoundError

    read_stats = pd.read_csv(fastcat_output, sep="\t")
    read_stats.rename(columns={"read_id": "readID"}, inplace=True)
    read_stats = read_stats.set_index("readID")
    classifications = pd.read_csv(tsv_path, sep="\t")

    tax_groups = classifications["taxID"].unique()
    assignments = None
    if split_by_rank:
        assignments = by_rule(
            tax_groups,
            rules=f"{split_by_rank}:{split_by_rank}:1",
            human=human_labels,
            delimiter=delimiter,
        )
    elif split_by_taxid:
        assignments = by_rule(
            tax_groups,
            rules=f"{split_by_taxid}::{split_by_taxid}",
            human=human_labels,
            delimiter=delimiter,
        )
    elif split_by_status:
        assignments = by_status(tax_groups)
    elif split_by_rule:
        assignments = by_rule(tax_groups, rules=split_by_rule)

    if not assignments:
        raise Exception("Something weird has happened")

    lineage_master_table = _create_lineage_master(tax_groups)
    assignment_df = pd.DataFrame.from_dict(
        assignments, orient="index", columns=["label"]
    )
    assignment_df = lineage_master_table.join(assignment_df)
    read_classification_master = classifications.join(
        assignment_df, on="taxID"
    )
    read_classification_master = read_classification_master.join(
        read_stats, on="readID"
    )
    with open(output_dir / "read_classification_master.tsv", "wb") as f:
        read_classification_master.to_csv(f, na_rep="-1", index=False)

    print(
        read_classification_master[["readID", "label"]]
        .groupby("label")
        .count()
    )


if __name__ == "__main__":
    main()
